# Configuration for Cog ⚙️
# Reference: https://cog.run/yaml

build:
  # set to true if your model requires a GPU
  gpu: true
  cuda: "12.1"

  # python version in the form '3.11' or '3.11.4'
  python_version: "3.10.9"

  # a list of packages in the format <package-name>==<version>
  python_packages:
    - "torch==2.1.1"
    - "torchvision==0.16.1"
    - "opencv-python==4.9.0.80"
    - "diffusers==0.30.2"
    - "transformers==4.46.3" # was "transformers==4.39.3" before
    - "tokenizers==0.20.3" # was "tokenizers==0.15.2" before 
    - "accelerate==1.1.1"
    - "pandas==2.0.3"
    - "numpy==1.24.4"
    - "einops==0.7.0"
    - "tqdm==4.66.2"
    - "loguru==0.7.2"
    - "imageio==2.34.0"
    - "imageio-ffmpeg==0.5.1"
    - "safetensors==0.4.3"
    # - "git+https://github.com/Dao-AILab/flash-attention.git@v2.5.9.post1"

  # commands run after the environment is setup
  run:
    # - python -m pip install git+https://github.com/Dao-AILab/flash-attention.git@v2.5.9.post1
    - FLASH_ATTENTION_SKIP_CUDA_BUILD=TRUE pip install flash-attn --no-build-isolation
    - curl -o /usr/local/bin/pget -L "https://github.com/replicate/pget/releases/download/v0.8.2/pget_linux_x86_64" && chmod +x /usr/local/bin/pget

# predict.py defines how predictions are run on your model
predict: "predict.py:Predictor"
